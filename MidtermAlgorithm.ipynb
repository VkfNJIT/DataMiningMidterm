{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65dd992a-2994-4709-a3e3-cff517163712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# List of all the datasets that are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b99a811-aff3-4d21-a227-92b744e647fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def item_k_support_possibilities(item_names, k):\n",
    "\n",
    "    item_k_arrange = combinations(item_names, k)\n",
    "    possibilities_of_k_items = [item for item in item_k_arrange]\n",
    "    return possibilities_of_k_items\n",
    "\n",
    "def count_itemsets_for_k(current_itemset, transactions, k):\n",
    "    item_k_filter = [name for name in current_itemset.keys()]\n",
    "    item_k_frequent_names = item_k_support_possibilities(item_k_filter, k)\n",
    "    itemset_k = {}\n",
    "    for item in item_k_frequent_names:\n",
    "        count_occ = sum(1 for transact in transactions if set(item).issubset(transact))\n",
    "        itemset_k[tuple(item)] = float(count_occ) / len(transactions)\n",
    "    return itemset_k\n",
    "    \n",
    "def get_itemsets_with_confidence(total_itemset_frequent, min_confidence):\n",
    "    itemset_confidence = {}\n",
    "    itemset_copy = total_itemset_frequent.copy()\n",
    "    for key, val in total_itemset_frequent.items():\n",
    "        if isinstance(key, tuple):\n",
    "            if len(key) == 2:\n",
    "                first = key[0]\n",
    "                second = key[-1]\n",
    "                confidence_val = val / total_itemset_frequent[first]\n",
    "                if confidence_val >= min_confidence:\n",
    "                    itemset_confidence[(first, second)] = confidence_val\n",
    "                first_reverse = key[-1]\n",
    "                second_reverse = key[0]\n",
    "                confidence_val = val / itemset_copy[first_reverse]\n",
    "                if confidence_val >= min_confidence:\n",
    "                    itemset_confidence[(first_reverse, second_reverse)] = confidence_val\n",
    "                    itemset_copy[(first_reverse, second_reverse)] = val\n",
    "                \n",
    "            elif len(key) > 2:    \n",
    "                for i in range(1, len(key)+1):\n",
    "                    for first in combinations(list(key), i):\n",
    "                        second = tuple(set(key).difference(set(first))) # This will get what comes after ->\n",
    "                        if len(second) > 0:\n",
    "                            first = tuple(sorted(first))\n",
    "                            if first in itemset_copy:\n",
    "                                \n",
    "                                confidence_val = float(val)/itemset_copy[first]\n",
    "                                if confidence_val >= min_confidence:\n",
    "                                    itemset_confidence[(first, second)] = confidence_val\n",
    "                                    itemset_copy[(first, second)] = val\n",
    "                            else:\n",
    "                                if len(first) == 1:\n",
    "                                    confidence_val = val / itemset_copy[first[0]]\n",
    "                                    if confidence_val >= min_confidence:\n",
    "                                        itemset_confidence[(first, second)] = confidence_val\n",
    "                                        itemset_copy[(first, second)] = val\n",
    "                                else:\n",
    "                                    for item in total_itemset_frequent.keys():\n",
    "                                        if len(set(item).difference(set(first))) == 0:\n",
    "                                            confidence_val = val / itemset_copy[item]\n",
    "                                            if confidence_val >= min_confidence:\n",
    "                                                itemset_confidence[(first, second)] = confidence_val\n",
    "                                                itemset_copy[(first, second)] = val         \n",
    "         \n",
    "    return itemset_confidence, itemset_copy\n",
    "\n",
    "def collect_frequent_itemset(unfilter_dict_k, min_support):\n",
    "    filtered_dict = {}\n",
    "    for key, val in unfilter_dict_k.items():\n",
    "        if val >= min_support:\n",
    "            itemsetkey = {key}\n",
    "            filtered_dict[key] = val\n",
    "    return filtered_dict\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b1ee8ec-e912-4457-8030-5d7f3c6ad00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the store number for the dataset that you want:\n",
      "1. Amazon\n",
      "2. Best Buy\n",
      "3. K-mart\n",
      "4. Nike\n",
      "5. Ace Hardware\n",
      " 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected the ace_hardware dataset\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the minimum support percent that you want (1 to 100):\n",
      " 40\n",
      "Please enter the minimum confidence percent that you want (1 to 100):\n",
      " 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itemset: Nails, Support: 0.45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loads a dictionary of datasets that you can select by number\n",
    "selected_stores = {1: \"amazon\", 2: \"best_buy\", 3: \"k-mart\", 4: \"nike\", 5: \"ace_hardware\"}\n",
    "try:\n",
    "    selected_id = int(input(\n",
    "    \"Enter the store number for the dataset that you want:\\n1. Amazon\\n2. Best Buy\\n3. K-mart\\n4. Nike\\n5. Ace Hardware\\n\"))\n",
    "    if selected_id not in selected_stores.keys():\n",
    "        print(\"invalid number, There are only 5 choices!Try again next time\")\n",
    "        sys.exit()\n",
    "except ValueError:\n",
    "    print(\"Invalid input! There are only 5 choices, please enter a valid number(1 to 5) next time\")\n",
    "    sys.exit()\n",
    "item_names = pd.read_csv(f\"{os.getcwd()}/{selected_stores[selected_id]}_items.csv\")\n",
    "transactions = pd.read_csv(f\"{os.getcwd()}/{selected_stores[selected_id]}_transactions.csv\")\n",
    "print(f\"You have selected the {selected_stores[selected_id]} dataset\")\n",
    "\n",
    "# Enter the minimum support and the minimum confidence \n",
    "min_support = float(input(\"Please enter the minimum support percent that you want (1 to 100):\\n\"))\n",
    "min_support /= 100\n",
    "min_confidence = float(input(\"Please enter the minimum confidence percent that you want (1 to 100):\\n\"))\n",
    "min_confidence /= 100\n",
    "\n",
    "itemset_k1 = item_names.set_index(\"Item Name\").to_dict()[\"Item #\"]\n",
    "\n",
    "# This technique Only for the itemsets where k = 1 \n",
    "# Split the string by comma to seperate each string in a row\n",
    "item_k1_names = [name for name in item_names[\"Item Name\"]]\n",
    "\n",
    "item_k1_count = transactions['Transaction'].str.split(\", \").explode().value_counts()\n",
    "\n",
    "item_k1 = item_k1_count.to_dict()\n",
    "\n",
    "# Get the support value for each itemset-1\n",
    "for k, _ in itemset_k1.items():\n",
    "    if k not in item_k1:\n",
    "        itemset_k1[k] = float(0)\n",
    "    else: \n",
    "        itemset_k1[k] = float(item_k1[k]) / len(transactions[\"Transaction\"])\n",
    "itemset_frequent_k1 = collect_frequent_itemset(itemset_k1, min_support)\n",
    "item_k = transactions['Transaction'].str.split(\", \").to_list()\n",
    "itemset_k = {}\n",
    "itemset_frequent_k = itemset_frequent_k1\n",
    "k_val = 2\n",
    "updated_itemset = itemset_frequent_k1\n",
    "while len(itemset_frequent_k) >= k_val:\n",
    "    itemset_k = count_itemsets_for_k(itemset_frequent_k1, item_k, k_val)\n",
    "    itemset_frequent_k = collect_frequent_itemset(itemset_k, min_support)\n",
    "    updated_itemset.update(itemset_frequent_k)\n",
    "    k_val += 1\n",
    "for key_s, val_s in updated_itemset.items():\n",
    "    print(f\"Itemset: {key_s}, Support: {val_s}\\n\")\n",
    "item_conf, item_supp = get_itemsets_with_confidence(updated_itemset, min_confidence)\n",
    "print()\n",
    "rule_ci = 1\n",
    "for key_c,val_c in item_conf.items():\n",
    "    if len(key_c) == 2 and val_c > 0:\n",
    "        print(\n",
    "        f\"Rule {rule_ci}:{set(key_c[0:1])} -> {set(key_c[1:])}\\nConfidence: {val_c*100:.2f}%\\nSupport: {item_supp[key_c]*100:.2f}%\")\n",
    "        rule_ci += 1\n",
    "        print()\n",
    "    else:\n",
    "        for i in range(len(key_c)-1):\n",
    "            if len(val_c) > 0:\n",
    "                print(\n",
    "        f\"Rule {rule_ci}:{set(key_c[0:i+1])} -> {set(key_c[i+1:])}\\nConfidence: {val_c*100:.2f}%\\nSupport: {item_supp[key_c]*100:.2f}%\")\n",
    "                rule_ci += 1\n",
    "                print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "455a461e-0648-45ce-8f21-fdb425839206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Apriori Library\n",
      "   support itemsets\n",
      "0     0.45  (Nails)\n",
      "\n",
      "FP Tree Library\n",
      "   support itemsets\n",
      "0     0.45  (Nails)\n",
      "\n",
      "Association Rules Library\n",
      "Empty DataFrame\n",
      "Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(item_k).transform(item_k)\n",
    "dataframe = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "checking_apriori = apriori(dataframe, min_support=min_support, use_colnames=True)\n",
    "print()\n",
    "print(\"Apriori Library\")\n",
    "print(checking_apriori)\n",
    "print()\n",
    "checking_fpgrowth = fpgrowth(dataframe, min_support=min_support, use_colnames=True)\n",
    "print(\"FP Tree Library\")\n",
    "print(checking_fpgrowth)\n",
    "ar = association_rules(checking_apriori, metric='confidence', min_threshold=min_confidence)\n",
    "print()\n",
    "print(\"Association Rules Library\")\n",
    "print(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1b3bdc-8687-4cf4-ac3a-db01db6685b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
